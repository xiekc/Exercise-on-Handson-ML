{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In __enter__()\n",
      "sample: Foo\n",
      "In __exit__()\n"
     ]
    }
   ],
   "source": [
    "#https://www.cnblogs.com/DswCnblog/p/6126588.html\n",
    "#usage of 'with'\n",
    "'''\n",
    "file = open(\"/tmp/foo.txt\")\n",
    "try:\n",
    "    data = file.read()\n",
    "finally:\n",
    "    file.close()  \n",
    "<=>\n",
    "with open(\"/tmp/foo.txt\") as file:\n",
    "    data = file.read()\n",
    "'''\n",
    " \n",
    "class Sample:\n",
    "    def __enter__(self):\n",
    "        print (\"In __enter__()\")\n",
    "        return (\"Foo\")\n",
    " \n",
    "    def __exit__(self, type, value, trace):\n",
    "        print (\"In __exit__()\")\n",
    "\n",
    "with Sample() as sample:\n",
    "    print (\"sample:\", sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "totally cost 0.2016560444725175\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "time_start=time.clock()\n",
    "\n",
    "one=tf.constant(1)\n",
    "x1=tf.Variable(0)\n",
    "#temp=tf.add(x1,one)\n",
    "x1_update=tf.assign(x1,tf.add(x1,one))\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in range(1000):\n",
    "        sess.run(x1_update)\n",
    "    print(x1.eval())\n",
    "    \n",
    "time_end=time.clock()\n",
    "print('totally cost',time_end-time_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running a Graph in a Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.Variable(3,name='x')\n",
    "y=tf.Variable(4,name='y')\n",
    "f=x*x*y+y+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess=tf.Session()\n",
    "sess.run(x.initializer)\n",
    "sess.run(y.initializer)\n",
    "print(sess.run(f))\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    x.initializer.run()\n",
    "    y.initializer.run()\n",
    "    print(f.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "init =tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    print(f.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "sess=tf.InteractiveSession()\n",
    "init.run()\n",
    "print(f.eval())\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Managing Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.graph is tf.get_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "graph =tf.Graph()\n",
    "with graph.as_default():\n",
    "    x2=tf.Variable(2)\n",
    "print(x2.graph is graph)\n",
    "print(x2.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10, 15]\n"
     ]
    }
   ],
   "source": [
    "#equation solver\n",
    "w=tf.constant(3)\n",
    "x=w+2\n",
    "y=x+5\n",
    "z=x*3\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run([y,z]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.7185181e+01]\n",
      " [ 4.3633747e-01]\n",
      " [ 9.3952334e-03]\n",
      " [-1.0711310e-01]\n",
      " [ 6.4479220e-01]\n",
      " [-4.0338000e-06]\n",
      " [-3.7813708e-03]\n",
      " [-4.2348403e-01]\n",
      " [-4.3721911e-01]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "housing=fetch_california_housing()\n",
    "m,n=housing.data.shape\n",
    "housing_data_plus_bias=np.c_[np.ones((m,1)),housing.data]\n",
    "\n",
    "X=tf.constant(housing_data_plus_bias,dtype=tf.float32)\n",
    "y=tf.constant(housing.target.reshape(-1,1),dtype=tf.float32)\n",
    "X_T=tf.transpose(X)\n",
    "theta=tf.matmul(tf.matmul(tf.matrix_inverse(tf.matmul(X_T,X)),X_T),y)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(theta.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaled_housing_data = scaler.fit_transform(housing.data)\n",
    "scaled_housing_data_plus_bias = np.c_[np.ones((m, 1)), scaled_housing_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  0 MSE= 6.646847\n",
      "Epoch:  30 MSE= 0.6654864\n",
      "Epoch:  60 MSE= 0.58900315\n",
      "Epoch:  90 MSE= 0.55545115\n",
      "Epoch:  120 MSE= 0.53997815\n",
      "Epoch:  150 MSE= 0.5324972\n",
      "Epoch:  180 MSE= 0.52871954\n",
      "Epoch:  210 MSE= 0.5267403\n",
      "Epoch:  240 MSE= 0.5256731\n",
      "Epoch:  270 MSE= 0.52508485\n",
      "Epoch:  300 MSE= 0.52475566\n",
      "[[ 2.0685577 ]\n",
      " [ 0.8509807 ]\n",
      " [ 0.12402568]\n",
      " [-0.30351254]\n",
      " [ 0.33606333]\n",
      " [-0.00286167]\n",
      " [-0.04022788]\n",
      " [-0.8413803 ]\n",
      " [-0.81440705]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "n_epochs=301\n",
    "learning_rate=0.1\n",
    "\n",
    "X=tf.constant(scaled_housing_data_plus_bias,dtype=tf.float32)\n",
    "y=tf.constant(housing.target.reshape(-1,1),dtype=tf.float32)\n",
    "theta=tf.Variable(tf.random_uniform([n+1,1],-1,1))\n",
    "y_pred=tf.matmul(X,theta)\n",
    "error=y_pred-y\n",
    "mse=tf.reduce_mean(tf.square(error))\n",
    "#gradients=tf.gradients(mse,[theta])[0]\n",
    "#training_op=tf.assign(theta,theta-learning_rate*gradients)\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op=optimizer.minimize(mse)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op)\n",
    "        if epoch % 30==0:\n",
    "            print('Epoch: ',epoch,'MSE=',mse.eval())\n",
    "    best_theta=theta.eval()\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feeding Data to the Training Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6. 7. 8.]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "A=tf.placeholder(tf.float32,shape=(None,3))\n",
    "B=A+5\n",
    "with tf.Session() as sess:\n",
    "    print(B.eval(feed_dict={A:[[1,2,3]]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X=tf.placeholder(tf.float32,shape=(None,n+1))\n",
    "y=tf.placeholder(tf.float32,shape=(None,1))\n",
    "batch_size=100\n",
    "n_epochs=10\n",
    "learning_rate=0.01\n",
    "n_batches=int(np.ceil(m/batch_size))\n",
    "\n",
    "theta=tf.Variable(tf.random_uniform([n+1,1],-1,1))\n",
    "y_pred=tf.matmul(X,theta)\n",
    "error=y_pred-y\n",
    "mse=tf.reduce_mean(tf.square(error))\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op=optimizer.minimize(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "init =tf.global_variables_initializer()\n",
    "\n",
    "def fetch_batch(epoch, batch_index, batch_size):\n",
    "    np.random.seed(epoch * n_batches + batch_index)  # not shown in the book\n",
    "    indices = np.random.randint(m, size=batch_size)  # not shown\n",
    "    X_batch = scaled_housing_data_plus_bias[indices] # not shown\n",
    "    y_batch = housing.target.reshape(-1, 1)[indices] # not shown\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.070146  ]\n",
      " [ 0.8378247 ]\n",
      " [ 0.11930648]\n",
      " [-0.26163596]\n",
      " [ 0.34127533]\n",
      " [ 0.00381156]\n",
      " [-0.01166134]\n",
      " [-0.8841386 ]\n",
      " [-0.849708  ]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch,y_batch=fetch_batch(epoch,batch_index,batch_size)\n",
    "            sess.run(training_op,feed_dict={X:X_batch,y:y_batch})\n",
    "    print(theta.eval())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Restoring Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0685577e+00]\n",
      " [ 6.9473344e-01]\n",
      " [ 1.2223595e-01]\n",
      " [ 4.3138064e-02]\n",
      " [ 2.6788551e-02]\n",
      " [-1.4847987e-03]\n",
      " [-3.6744937e-02]\n",
      " [-1.0011474e+00]\n",
      " [-9.5349991e-01]]\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "n_epochs=100\n",
    "learning_rate=0.1\n",
    "X=tf.constant(scaled_housing_data_plus_bias,dtype=tf.float32)\n",
    "y=tf.constant(housing.target.reshape(-1,1),dtype=tf.float32)\n",
    "theta=tf.Variable(tf.random_uniform([n+1,1],-1,1))\n",
    "y_pred=tf.matmul(X,theta)\n",
    "error=y-y_pred\n",
    "mse=tf.reduce_mean(tf.square(error))\n",
    "optimizer=tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op=optimizer.minimize(mse)\n",
    "\n",
    "init=tf.global_variables_initializer()\n",
    "saver=tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(n_epochs):\n",
    "        sess.run(training_op)\n",
    "        if epoch %10==0:\n",
    "            saver.save(sess,'C:/Users/xiekch/Documents/ML/handson-ml/my/tmp/my_model.ckpt')\n",
    "    best_theta=theta.eval()\n",
    "    saver.save(sess,'C:/Users/xiekch/Documents/ML/handson-ml/my/tmp/my_model_final.ckpt')\n",
    "print(best_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:/Users/xiekch/Documents/ML/handson-ml/my/tmp/my_model_final.ckpt\n",
      "[[ 2.0685577e+00]\n",
      " [ 6.9473344e-01]\n",
      " [ 1.2223595e-01]\n",
      " [ 4.3138064e-02]\n",
      " [ 2.6788551e-02]\n",
      " [-1.4847987e-03]\n",
      " [-3.6744937e-02]\n",
      " [-1.0011474e+00]\n",
      " [-9.5349991e-01]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,'C:/Users/xiekch/Documents/ML/handson-ml/my/tmp/my_model_final.ckpt')\n",
    "    best_theta_restored=theta.eval()\n",
    "print(best_theta_restored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#best_theta==best_theta_restored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now=datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "root_logdir='tf_logs'\n",
    "logdir='{}/run-{}/'.format(root_logdir,now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 1000\n",
    "learning_rate = 0.01\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=(None, n + 1), name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=(None, 1), name=\"y\")\n",
    "theta = tf.Variable(tf.random_uniform([n + 1, 1], -1.0, 1.0, seed=42), name=\"theta\")\n",
    "y_pred = tf.matmul(X, theta, name=\"predictions\")\n",
    "error = y_pred - y\n",
    "mse = tf.reduce_mean(tf.square(error), name=\"mse\")\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(mse)\n",
    "\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 100\n",
    "n_batches = int(np.ceil(m / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:                                                        # not shown in the book\n",
    "    sess.run(init)                                                                # not shown\n",
    "\n",
    "    for epoch in range(n_epochs):                                                 # not shown\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = fetch_batch(epoch, batch_index, batch_size)\n",
    "            if batch_index % 10 == 0:\n",
    "                summary_str = mse_summary.eval(feed_dict={X: X_batch, y: y_batch})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "\n",
    "    best_theta = theta.eval()     \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PS C:\\Users\\xiekch\\Documents\\ML\\handson-ml\\my\\tf_logs> tensorboard --logdir=\"run-2018081\n",
    "#2095636\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharing Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('relu'):\n",
    "    threshold=tf.get_variable('threshold',shape=(),initializer=tf.constant_initializer(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'relu/threshold:0' shape=() dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('relu',reuse=True):\n",
    "    threshold=tf.get_variable('threshold')\n",
    "    print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'relu/threshold:0' shape=() dtype=float32_ref>\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope('relu') as scope:\n",
    "    scope.reuse_variables()\n",
    "    threshold=tf.get_variable('threshold')\n",
    "    print(threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
