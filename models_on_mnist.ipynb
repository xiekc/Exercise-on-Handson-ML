{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn as sk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.astype(np.float32).reshape(-1,28*28)/255\n",
    "X_test= X_test.astype(np.float32).reshape(-1, 28*28) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$s_k(x)={\\theta_k}^T\\cdot x$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "softmax=LogisticRegression(multi_class='multinomial',solver='lbfgs',C=10)\n",
    "softmax.fit(X_train,y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax=joblib.load('./saved_models/softmax_on_mnist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred_sm=softmax.predict(X_test)\n",
    "print(accuracy_score(y_test,y_pred_sm))\n",
    "#0.9258"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "#cross validation\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "y_scores_sm=cross_val_predict(softmax,X_train_sm,y_train,cv=3,method='predict')\n",
    "method : string, optional, default: ‘predict’\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_train,y_scores_sm))\n",
    "#0.91685\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./saved_models/softmax_on_mnist.pkl']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(softmax,'./saved_models/softmax_on_mnist.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$s_k(x)={\\theta_x}^T\\cdot x+b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-76f44b0bcf8f>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./my_datasets_mnist/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting ./my_datasets_mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting ./my_datasets_mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./my_datasets_mnist/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From D:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist =input_data.read_data_sets('./my_datasets_mnist/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs=28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=tf.placeholder(tf.float32,shape=(None,n_inputs),name='X')\n",
    "y=tf.placeholder(tf.int64,shape=(None),name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stddev=np.sqrt(2/(n_inputs+10))\n",
    "W_init=tf.truncated_normal([n_inputs,10],stddev=stddev)\n",
    "W=tf.Variable(W_init)\n",
    "b=tf.Variable(np.ones(10).astype(np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits=tf.matmul(X,W)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy=tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y,logits=logits)\n",
    "loss=tf.reduce_mean(entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "#maybe another way\n",
    "y_pro=tf.nn.softmax(logits)\n",
    "#y = tf.placeholder(tf.float, [None,10])\n",
    "entropy = -tf.reduce_sum(y*tf.log(y_pro))\n",
    "loss=entropy\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: Why not use $-accuracy$ as loss function?  \n",
    "A: Accuracy is based on test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy=tf.reduce_mean(tf.cast(tf.nn.in_top_k(logits,y,1),tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#another way\n",
    "accuracy=tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits,axis=1),y),tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_op=tf.train.GradientDescentOptimizer(0.01).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=tf.global_variables_initializer()\n",
    "n_epochs=50\n",
    "batch_size=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Test accuracy: 0.8712\n",
      "1 Test accuracy: 0.8858\n",
      "2 Test accuracy: 0.8945\n",
      "3 Test accuracy: 0.9003\n",
      "4 Test accuracy: 0.9024\n",
      "5 Test accuracy: 0.9056\n",
      "6 Test accuracy: 0.9071\n",
      "7 Test accuracy: 0.9097\n",
      "8 Test accuracy: 0.9104\n",
      "9 Test accuracy: 0.9111\n",
      "10 Test accuracy: 0.9123\n",
      "11 Test accuracy: 0.9133\n",
      "12 Test accuracy: 0.9134\n",
      "13 Test accuracy: 0.9138\n",
      "14 Test accuracy: 0.9144\n",
      "15 Test accuracy: 0.9146\n",
      "16 Test accuracy: 0.9158\n",
      "17 Test accuracy: 0.9155\n",
      "18 Test accuracy: 0.9149\n",
      "19 Test accuracy: 0.9167\n",
      "20 Test accuracy: 0.9168\n",
      "21 Test accuracy: 0.9172\n",
      "22 Test accuracy: 0.9172\n",
      "23 Test accuracy: 0.9182\n",
      "24 Test accuracy: 0.9195\n",
      "25 Test accuracy: 0.9179\n",
      "26 Test accuracy: 0.9181\n",
      "27 Test accuracy: 0.9184\n",
      "28 Test accuracy: 0.9184\n",
      "29 Test accuracy: 0.9192\n",
      "30 Test accuracy: 0.9201\n",
      "31 Test accuracy: 0.921\n",
      "32 Test accuracy: 0.9204\n",
      "33 Test accuracy: 0.9199\n",
      "34 Test accuracy: 0.9204\n",
      "35 Test accuracy: 0.9199\n",
      "36 Test accuracy: 0.9197\n",
      "37 Test accuracy: 0.9204\n",
      "38 Test accuracy: 0.9213\n",
      "39 Test accuracy: 0.9209\n",
      "40 Test accuracy: 0.9219\n",
      "41 Test accuracy: 0.9217\n",
      "42 Test accuracy: 0.9214\n",
      "43 Test accuracy: 0.9208\n",
      "44 Test accuracy: 0.9215\n",
      "45 Test accuracy: 0.9218\n",
      "46 Test accuracy: 0.9216\n",
      "47 Test accuracy: 0.9222\n",
      "48 Test accuracy: 0.9222\n",
      "49 Test accuracy: 0.9215\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for iteration in range(mnist.train.num_examples//batch_size):\n",
    "            X_batch,y_batch=mnist.train.next_batch(batch_size)\n",
    "            training_op.run(feed_dict={X:X_batch,\n",
    "                                       y:y_batch})\n",
    "            #print(y_batch)\n",
    "            #print(logits.eval(feed_dict={X:X_batch,y:y_batch}))\n",
    "        acc_test=accuracy.eval(feed_dict={X:mnist.test.images,y:mnist.test.labels})\n",
    "        print(epoch,\"Test accuracy:\",acc_test)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 784)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Learning with ANNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
